{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "LR_SHAPE = (16, 16)  # Low resolution shape\n",
    "HR_SHAPE = (128, 128)  # High resolution shape\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "INPUT_PATH = \"/home/diya/Projects/super_resolution/dataset/\"  # Update this path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_wandb():\n",
    "    \"\"\"Initialize Weights & Biases tracking\"\"\"\n",
    "    wandb.init(\n",
    "        project=\"flow-super-resolution-fno\",\n",
    "        config={\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"epochs\": NUM_EPOCHS,\n",
    "            \"model\": \"FNO3D\",\n",
    "            \"architecture\": \"modes1=8, modes2=8, modes3=8, width=64\"\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.randn(in_channels, out_channels, modes1, modes2, 2))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.randn(in_channels, out_channels, modes1, modes2, 2))\n",
    "\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        return torch.stack([\n",
    "            input[..., 0] * weights[..., 0] - input[..., 1] * weights[..., 1],\n",
    "            input[..., 0] * weights[..., 1] + input[..., 1] * weights[..., 0]\n",
    "        ], dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        size1, size2 = x.shape[1], x.shape[2]\n",
    "\n",
    "        x_ft = torch.fft.rfft2(x, dim=[1, 2])\n",
    "        x_ft = torch.stack([x_ft.real, x_ft.imag], dim=-1)\n",
    "\n",
    "        out_ft = torch.zeros(batchsize, size1, size2//2 + 1, 2, device=x.device)\n",
    "        out_ft[:, :self.modes1, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, -self.modes1:, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        x = torch.complex(out_ft[..., 0], out_ft[..., 1])\n",
    "        x = torch.fft.irfft2(x, s=(size1, size2), dim=[1, 2])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNO2d(nn.Module):\n",
    "    def __init__(self, modes1, modes2, width=64, in_channels=4, out_channels=4):\n",
    "        super(FNO2d, self).__init__()\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.width = width\n",
    "\n",
    "        self.fc0 = nn.Linear(in_channels, self.width)\n",
    "        \n",
    "        self.conv0 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv1 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv2 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        \n",
    "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
    "        \n",
    "        # Increased intermediate dimensions for better upscaling\n",
    "        self.fc1 = nn.Linear(self.width, 256)\n",
    "        self.fc2 = nn.Linear(256, out_channels)\n",
    "        \n",
    "        # Learnable interpolation weight\n",
    "        self.alpha = nn.Parameter(torch.tensor(0.5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_original = x\n",
    "        \n",
    "        x = self.fc0(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
    "        \n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "        \n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "        \n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        \n",
    "        # Upscale to target resolution before final projection\n",
    "        x = F.interpolate(x, size=HR_SHAPE, mode='bicubic', align_corners=False)\n",
    "        \n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Bicubic interpolation of original input\n",
    "        x_bicubic = F.interpolate(x_original, size=HR_SHAPE, mode='bicubic', align_corners=False)\n",
    "        \n",
    "        return self.alpha * x + (1 - self.alpha) * x_bicubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from common.config import INPUT_PATH, LR_SHAPE, HR_SHAPE\n",
    "\n",
    "class FileNotFoundOrEmptyError(Exception):\n",
    "    \"\"\"Custom exception for file not found or empty file cases.\"\"\"\n",
    "    pass\n",
    "\n",
    "def verify_file_exists(filepath):\n",
    "    \"\"\"\n",
    "    Verify if a file exists and is not empty.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the file to verify\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if file exists and is not empty\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundOrEmptyError: If file doesn't exist or is empty\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundOrEmptyError(f\"File not found: {filepath}\")\n",
    "    \n",
    "    if os.path.getsize(filepath) == 0:\n",
    "        raise FileNotFoundOrEmptyError(f\"File is empty: {filepath}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def load_binary_file(filepath, shape):\n",
    "    \"\"\"\n",
    "    Load a binary file with error handling.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the binary file\n",
    "        shape (tuple): Expected shape of the data\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Loaded and reshaped data\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If data cannot be reshaped to expected shape\n",
    "        FileNotFoundOrEmptyError: If file doesn't exist or is empty\n",
    "    \"\"\"\n",
    "    try:\n",
    "        verify_file_exists(filepath)\n",
    "        data = np.fromfile(filepath, dtype=\"<f4\")\n",
    "        \n",
    "        expected_size = np.prod(shape)\n",
    "        if data.size != expected_size:\n",
    "            raise ValueError(\n",
    "                f\"Data size mismatch. Expected {expected_size} elements \"\n",
    "                f\"for shape {shape}, but got {data.size} elements\"\n",
    "            )\n",
    "        \n",
    "        return data.reshape(shape)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise type(e)(\n",
    "            f\"Error loading file {filepath}: {str(e)}\"\n",
    "        ) from e\n",
    "\n",
    "def load_csv_data(mode='train'):\n",
    "    \"\"\"\n",
    "    Load CSV metadata file.\n",
    "    \n",
    "    Args:\n",
    "        mode (str): Dataset mode ('train', 'val', or 'test')\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded CSV data\n",
    "    \"\"\"\n",
    "    csv_path = f'{INPUT_PATH}{mode}.csv'\n",
    "    try:\n",
    "        verify_file_exists(csv_path)\n",
    "        return pd.read_csv(csv_path)\n",
    "    except Exception as e:\n",
    "        raise type(e)(\n",
    "            f\"Error loading CSV file {csv_path}: {str(e)}\"\n",
    "        ) from e\n",
    "\n",
    "def get_xy(idx, csv_file, mode='train'):\n",
    "    \"\"\"\n",
    "    Load LR and HR data for a single sample.\n",
    "    \n",
    "    Args:\n",
    "        idx (int): Sample index\n",
    "        csv_file (pd.DataFrame): CSV metadata\n",
    "        mode (str): Dataset mode ('train', 'val', or 'test')\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (LR data, HR data) for train/val, or LR data for test\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate paths\n",
    "        LR_path = f\"{INPUT_PATH}flowfields/LR/{mode}\"\n",
    "        HR_path = f\"{INPUT_PATH}flowfields/HR/{mode}\" if mode != 'test' else None\n",
    "        \n",
    "        if not os.path.exists(LR_path):\n",
    "            raise FileNotFoundOrEmptyError(f\"LR directory not found: {LR_path}\")\n",
    "        if HR_path and not os.path.exists(HR_path):\n",
    "            raise FileNotFoundOrEmptyError(f\"HR directory not found: {HR_path}\")\n",
    "        \n",
    "        # Load LR data\n",
    "        lr_files = {\n",
    "            'rho': f\"{LR_path}/{csv_file['rho_filename'][idx]}\",\n",
    "            'ux': f\"{LR_path}/{csv_file['ux_filename'][idx]}\",\n",
    "            'uy': f\"{LR_path}/{csv_file['uy_filename'][idx]}\",\n",
    "            'uz': f\"{LR_path}/{csv_file['uz_filename'][idx]}\"\n",
    "        }\n",
    "        \n",
    "        lr_data = {\n",
    "            name: load_binary_file(filepath, LR_SHAPE)\n",
    "            for name, filepath in lr_files.items()\n",
    "        }\n",
    "        \n",
    "        X = torch.stack([\n",
    "            torch.from_numpy(lr_data[name]).float()\n",
    "            for name in ['rho', 'ux', 'uy', 'uz']\n",
    "        ], dim=2)\n",
    "        \n",
    "        if mode != 'test':\n",
    "            # Load HR data\n",
    "            hr_files = {\n",
    "                'rho': f\"{HR_path}/{csv_file['rho_filename'][idx]}\",\n",
    "                'ux': f\"{HR_path}/{csv_file['ux_filename'][idx]}\",\n",
    "                'uy': f\"{HR_path}/{csv_file['uy_filename'][idx]}\",\n",
    "                'uz': f\"{HR_path}/{csv_file['uz_filename'][idx]}\"\n",
    "            }\n",
    "            \n",
    "            hr_data = {\n",
    "                name: load_binary_file(filepath, HR_SHAPE)\n",
    "                for name, filepath in hr_files.items()\n",
    "            }\n",
    "            \n",
    "            Y = torch.stack([\n",
    "                torch.from_numpy(hr_data[name]).float()\n",
    "                for name in ['rho', 'ux', 'uy', 'uz']\n",
    "            ], dim=2)\n",
    "            \n",
    "            return X, Y\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise type(e)(\n",
    "            f\"Error processing sample {idx} in mode {mode}: {str(e)}\"\n",
    "        ) from e\n",
    "\n",
    "def load_data(mode='train'):\n",
    "    \"\"\"\n",
    "    Load complete dataset.\n",
    "    \n",
    "    Args:\n",
    "        mode (str): Dataset mode ('train', 'val', or 'test')\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (X, Y) for train/val, or X for test\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Loading {mode} dataset...\")\n",
    "        df = load_csv_data(mode)\n",
    "        print(f\"Found {len(df)} samples in {mode} CSV.\")\n",
    "        \n",
    "        data = []\n",
    "        for i in range(len(df)):\n",
    "            try:\n",
    "                sample_data = get_xy(i, df, mode)\n",
    "                data.append(sample_data)\n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(f\"Processed {i + 1}/{len(df)} samples...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing sample {i}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if not data:\n",
    "            raise ValueError(f\"No valid samples found in {mode} dataset\")\n",
    "        \n",
    "        if mode != 'test':\n",
    "            X, Y = zip(*data)\n",
    "            return torch.stack(X), torch.stack(Y)\n",
    "        return torch.stack(data)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise type(e)(\n",
    "            f\"Error loading {mode} dataset: {str(e)}\"\n",
    "        ) from e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowFieldDataset(Dataset):\n",
    "    def __init__(self, csv_file, mode='train'):\n",
    "        self.csv_file = csv_file\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode != 'test':\n",
    "            X, Y = get_xy(idx, self.csv_file, self.mode)\n",
    "            return X, Y\n",
    "        else:\n",
    "            return get_xy(idx, self.csv_file, self.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(pred, target):\n",
    "    # MSE Loss\n",
    "    mse_loss = F.mse_loss(pred, target)\n",
    "    \n",
    "    # Structural Similarity Loss (simplified version)\n",
    "    def ssim(img1, img2, window_size=11):\n",
    "        C1 = 0.01**2\n",
    "        C2 = 0.03**2\n",
    "        \n",
    "        mu1 = F.avg_pool3d(img1, window_size, stride=1, padding=window_size//2)\n",
    "        mu2 = F.avg_pool3d(img2, window_size, stride=1, padding=window_size//2)\n",
    "        \n",
    "        mu1_sq = mu1.pow(2)\n",
    "        mu2_sq = mu2.pow(2)\n",
    "        mu1_mu2 = mu1 * mu2\n",
    "        \n",
    "        sigma1_sq = F.avg_pool3d(img1 * img1, window_size, stride=1, padding=window_size//2) - mu1_sq\n",
    "        sigma2_sq = F.avg_pool3d(img2 * img2, window_size, stride=1, padding=window_size//2) - mu2_sq\n",
    "        sigma12 = F.avg_pool3d(img1 * img2, window_size, stride=1, padding=window_size//2) - mu1_mu2\n",
    "        \n",
    "        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / \\\n",
    "                   ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "        \n",
    "        return 1 - ssim_map.mean()\n",
    "    \n",
    "    ssim_loss = ssim(pred, target)\n",
    "    \n",
    "    return mse_loss + 0.1 * ssim_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, epoch):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
    "    \n",
    "    for batch_idx, (X, Y) in enumerate(pbar):\n",
    "        X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = combined_loss(pred, Y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        wandb.log({\n",
    "            \"train_batch_loss\": loss.item(),\n",
    "            \"batch\": batch_idx + epoch * len(train_loader)\n",
    "        })\n",
    "    \n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Setup\n",
    "    setup_wandb()\n",
    "    train_data, val_data, test_data = load_and_split_data()\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(train_data, val_data, test_data)\n",
    "    \n",
    "    # Initialize model with 2D architecture\n",
    "    model = FNO2d(\n",
    "        modes1=8, modes2=8,\n",
    "        width=64,\n",
    "        in_channels=4,\n",
    "        out_channels=4\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Rest of the training loop remains the same\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, epoch)\n",
    "        val_loss = validate(model, val_loader)\n",
    "        \n",
    "        wandb.log({\n",
    "            \"train_epoch_loss\": train_loss,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"epoch\": epoch,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(f\"Train Loss: {train_loss:.6f}\")\n",
    "        print(f\"Val Loss: {val_loss:.6f}\")\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            #save_checkpoint(model, optimizer, epoch, val_loss, 'best_model.pth')\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "    \n",
    "    # Final evaluation\n",
    "    print(\"Evaluating on test set...\")\n",
    "    predictions, metrics = evaluate(model, test_loader)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"test_mse\": np.mean(metrics['mse']) if metrics['mse'] else None,\n",
    "        \"test_psnr\": np.mean(metrics['psnr']) if metrics['psnr'] else None,\n",
    "        \"test_ssim\": np.mean(metrics['ssim']) if metrics['ssim'] else None\n",
    "    })\n",
    "    \n",
    "    torch.save(predictions, 'test_predictions.pt')\n",
    "    wandb.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from common.config import INPUT_PATH, LR_SHAPE, HR_SHAPE\n",
    "\n",
    "class FileNotFoundOrEmptyError(Exception):\n",
    "    \"\"\"Custom exception for file not found or empty file cases.\"\"\"\n",
    "    pass\n",
    "\n",
    "def verify_file_exists(filepath):\n",
    "    \"\"\"\n",
    "    Verify if a file exists and is not empty.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the file to verify\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if file exists and is not empty\n",
    "        \n",
    "    Raises:\n",
    "        FileNotFoundOrEmptyError: If file doesn't exist or is empty\n",
    "    \"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundOrEmptyError(f\"File not found: {filepath}\")\n",
    "    \n",
    "    if os.path.getsize(filepath) == 0:\n",
    "        raise FileNotFoundOrEmptyError(f\"File is empty: {filepath}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def load_binary_file(filepath, shape):\n",
    "    \"\"\"\n",
    "    Load a binary file with error handling.\n",
    "    \n",
    "    Args:\n",
    "        filepath (str): Path to the binary file\n",
    "        shape (tuple): Expected shape of the data\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Loaded and reshaped data\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If data cannot be reshaped to expected shape\n",
    "        FileNotFoundOrEmptyError: If file doesn't exist or is empty\n",
    "    \"\"\"\n",
    "    try:\n",
    "        verify_file_exists(filepath)\n",
    "        data = np.fromfile(filepath, dtype=\"<f4\")\n",
    "        \n",
    "        expected_size = np.prod(shape)\n",
    "        if data.size != expected_size:\n",
    "            raise ValueError(\n",
    "                f\"Data size mismatch. Expected {expected_size} elements \"\n",
    "                f\"for shape {shape}, but got {data.size} elements\"\n",
    "            )\n",
    "        \n",
    "        return data.reshape(shape)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise type(e)(\n",
    "            f\"Error loading file {filepath}: {str(e)}\"\n",
    "        ) from e\n",
    "\n",
    "def load_csv_data(mode='train'):\n",
    "    \"\"\"\n",
    "    Load CSV metadata file.\n",
    "    \n",
    "    Args:\n",
    "        mode (str): Dataset mode ('train', 'val', or 'test')\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded CSV data\n",
    "    \"\"\"\n",
    "    csv_path = f'{INPUT_PATH}{mode}.csv'\n",
    "    try:\n",
    "        verify_file_exists(csv_path)\n",
    "        return pd.read_csv(csv_path)\n",
    "    except Exception as e:\n",
    "        raise type(e)(\n",
    "            f\"Error loading CSV file {csv_path}: {str(e)}\"\n",
    "        ) from e\n",
    "\n",
    "def get_xy(idx, csv_file, mode='train'):\n",
    "    \"\"\"\n",
    "    Load LR and HR data for a single sample.\n",
    "    \n",
    "    Args:\n",
    "        idx (int): Sample index\n",
    "        csv_file (pd.DataFrame): CSV metadata\n",
    "        mode (str): Dataset mode ('train', 'val', or 'test')\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (LR data, HR data) for train/val, or LR data for test\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate paths\n",
    "        LR_path = f\"{INPUT_PATH}flowfields/LR/{mode}\"\n",
    "        HR_path = f\"{INPUT_PATH}flowfields/HR/{mode}\" if mode != 'test' else None\n",
    "        \n",
    "        if not os.path.exists(LR_path):\n",
    "            raise FileNotFoundOrEmptyError(f\"LR directory not found: {LR_path}\")\n",
    "        if HR_path and not os.path.exists(HR_path):\n",
    "            raise FileNotFoundOrEmptyError(f\"HR directory not found: {HR_path}\")\n",
    "        \n",
    "        # Load LR data\n",
    "        lr_files = {\n",
    "            'rho': f\"{LR_path}/{csv_file['rho_filename'][idx]}\",\n",
    "            'ux': f\"{LR_path}/{csv_file['ux_filename'][idx]}\",\n",
    "            'uy': f\"{LR_path}/{csv_file['uy_filename'][idx]}\",\n",
    "            'uz': f\"{LR_path}/{csv_file['uz_filename'][idx]}\"\n",
    "        }\n",
    "        \n",
    "        lr_data = {\n",
    "            name: load_binary_file(filepath, LR_SHAPE)\n",
    "            for name, filepath in lr_files.items()\n",
    "        }\n",
    "        \n",
    "        X = torch.stack([\n",
    "            torch.from_numpy(lr_data[name]).float()\n",
    "            for name in ['rho', 'ux', 'uy', 'uz']\n",
    "        ], dim=2)\n",
    "        \n",
    "        if mode != 'test':\n",
    "            # Load HR data\n",
    "            hr_files = {\n",
    "                'rho': f\"{HR_path}/{csv_file['rho_filename'][idx]}\",\n",
    "                'ux': f\"{HR_path}/{csv_file['ux_filename'][idx]}\",\n",
    "                'uy': f\"{HR_path}/{csv_file['uy_filename'][idx]}\",\n",
    "                'uz': f\"{HR_path}/{csv_file['uz_filename'][idx]}\"\n",
    "            }\n",
    "            \n",
    "            hr_data = {\n",
    "                name: load_binary_file(filepath, HR_SHAPE)\n",
    "                for name, filepath in hr_files.items()\n",
    "            }\n",
    "            \n",
    "            Y = torch.stack([\n",
    "                torch.from_numpy(hr_data[name]).float()\n",
    "                for name in ['rho', 'ux', 'uy', 'uz']\n",
    "            ], dim=2)\n",
    "            \n",
    "            return X, Y\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise type(e)(\n",
    "            f\"Error processing sample {idx} in mode {mode}: {str(e)}\"\n",
    "        ) from e\n",
    "\n",
    "def load_data(mode='train'):\n",
    "    \"\"\"\n",
    "    Load complete dataset.\n",
    "    \n",
    "    Args:\n",
    "        mode (str): Dataset mode ('train', 'val', or 'test')\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (X, Y) for train/val, or X for test\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Loading {mode} dataset...\")\n",
    "        df = load_csv_data(mode)\n",
    "        print(f\"Found {len(df)} samples in {mode} CSV.\")\n",
    "        \n",
    "        data = []\n",
    "        for i in range(len(df)):\n",
    "            try:\n",
    "                sample_data = get_xy(i, df, mode)\n",
    "                data.append(sample_data)\n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(f\"Processed {i + 1}/{len(df)} samples...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error processing sample {i}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        if not data:\n",
    "            raise ValueError(f\"No valid samples found in {mode} dataset\")\n",
    "        \n",
    "        if mode != 'test':\n",
    "            X, Y = zip(*data)\n",
    "            return torch.stack(X), torch.stack(Y)\n",
    "        return torch.stack(data)\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise type(e)(\n",
    "            f\"Error loading {mode} dataset: {str(e)}\"\n",
    "        ) from e\n",
    "\n",
    "class FlowFieldDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"PyTorch Dataset for flow field data.\"\"\"\n",
    "    \n",
    "    def __init__(self, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.df = load_csv_data(mode)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return get_xy(idx, self.df, self.mode)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/diya/Projects/super_resolution/src/wandb/run-20250122_155108-1zcfor49</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/starslab-iisc/flow-super-resolution-fno/runs/1zcfor49' target=\"_blank\">fno2d epochs = 100 batch size = 8 lr = 0.001alpha = 0.9</a></strong> to <a href='https://wandb.ai/starslab-iisc/flow-super-resolution-fno' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/starslab-iisc/flow-super-resolution-fno' target=\"_blank\">https://wandb.ai/starslab-iisc/flow-super-resolution-fno</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/starslab-iisc/flow-super-resolution-fno/runs/1zcfor49' target=\"_blank\">https://wandb.ai/starslab-iisc/flow-super-resolution-fno/runs/1zcfor49</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([8, 16, 16, 4])\n",
      "Target shape: torch.Size([8, 128, 128, 4])\n",
      "Upscale factor: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diya/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Train Loss: 195.860714\n",
      "Val Loss: 83.779851\n",
      "Epoch 2/100\n",
      "Train Loss: 78.941830\n",
      "Val Loss: 81.501471\n",
      "Epoch 3/100\n",
      "Train Loss: 78.143372\n",
      "Val Loss: 80.184355\n",
      "Epoch 4/100\n",
      "Train Loss: 78.223399\n",
      "Val Loss: 80.799161\n",
      "Epoch 5/100\n",
      "Train Loss: 76.796222\n",
      "Val Loss: 79.517639\n",
      "Epoch 6/100\n",
      "Train Loss: 56.567350\n",
      "Val Loss: 49.831389\n",
      "Epoch 7/100\n",
      "Train Loss: 43.183241\n",
      "Val Loss: 41.777826\n",
      "Epoch 8/100\n",
      "Train Loss: 39.114831\n",
      "Val Loss: 39.539489\n",
      "Epoch 9/100\n",
      "Train Loss: 37.268109\n",
      "Val Loss: 39.669312\n",
      "Epoch 10/100\n",
      "Train Loss: 37.135518\n",
      "Val Loss: 39.589305\n",
      "Epoch 11/100\n",
      "Train Loss: 36.522755\n",
      "Val Loss: 39.921098\n",
      "Epoch 12/100\n",
      "Train Loss: 37.095409\n",
      "Val Loss: 38.957983\n",
      "Epoch 13/100\n",
      "Train Loss: 36.259190\n",
      "Val Loss: 39.151574\n",
      "Epoch 14/100\n",
      "Train Loss: 36.028069\n",
      "Val Loss: 40.025992\n",
      "Epoch 15/100\n",
      "Train Loss: 38.318005\n",
      "Val Loss: 45.530299\n",
      "Epoch 16/100\n",
      "Train Loss: 36.208187\n",
      "Val Loss: 38.879397\n",
      "Epoch 17/100\n",
      "Train Loss: 35.098593\n",
      "Val Loss: 39.647652\n",
      "Epoch 18/100\n",
      "Train Loss: 37.002303\n",
      "Val Loss: 45.896144\n",
      "Epoch 19/100\n",
      "Train Loss: 36.657789\n",
      "Val Loss: 38.522696\n",
      "Epoch 20/100\n",
      "Train Loss: 31.307038\n",
      "Val Loss: 34.069408\n",
      "Epoch 21/100\n",
      "Train Loss: 28.306352\n",
      "Val Loss: 33.770512\n",
      "Epoch 22/100\n",
      "Train Loss: 27.431770\n",
      "Val Loss: 33.153387\n",
      "Epoch 23/100\n",
      "Train Loss: 26.776415\n",
      "Val Loss: 31.247448\n",
      "Epoch 24/100\n",
      "Train Loss: 26.080356\n",
      "Val Loss: 32.727066\n",
      "Epoch 25/100\n",
      "Train Loss: 26.063803\n",
      "Val Loss: 32.800228\n",
      "Epoch 26/100\n",
      "Train Loss: 27.965366\n",
      "Val Loss: 30.558362\n",
      "Epoch 27/100\n",
      "Train Loss: 24.892570\n",
      "Val Loss: 30.030996\n",
      "Epoch 28/100\n",
      "Train Loss: 23.428305\n",
      "Val Loss: 28.478257\n",
      "Epoch 29/100\n",
      "Train Loss: 22.317483\n",
      "Val Loss: 26.923422\n",
      "Epoch 30/100\n",
      "Train Loss: 22.359359\n",
      "Val Loss: 26.593153\n",
      "Epoch 31/100\n",
      "Train Loss: 21.510979\n",
      "Val Loss: 26.660471\n",
      "Epoch 32/100\n",
      "Train Loss: 20.617306\n",
      "Val Loss: 25.968720\n",
      "Epoch 33/100\n",
      "Train Loss: 19.771942\n",
      "Val Loss: 25.899321\n",
      "Epoch 34/100\n",
      "Train Loss: 20.415787\n",
      "Val Loss: 25.829120\n",
      "Epoch 35/100\n",
      "Train Loss: 19.759427\n",
      "Val Loss: 25.550580\n",
      "Epoch 36/100\n",
      "Train Loss: 19.857179\n",
      "Val Loss: 27.097118\n",
      "Epoch 37/100\n",
      "Train Loss: 19.383094\n",
      "Val Loss: 26.669790\n",
      "Epoch 38/100\n",
      "Train Loss: 19.458395\n",
      "Val Loss: 26.123004\n",
      "Epoch 39/100\n",
      "Train Loss: 19.297741\n",
      "Val Loss: 25.900219\n",
      "Epoch 40/100\n",
      "Train Loss: 19.405394\n",
      "Val Loss: 26.669057\n",
      "Epoch 41/100\n",
      "Train Loss: 18.892378\n",
      "Val Loss: 27.254204\n",
      "Epoch 42/100\n",
      "Train Loss: 17.319517\n",
      "Val Loss: 24.941926\n",
      "Epoch 43/100\n",
      "Train Loss: 16.633728\n",
      "Val Loss: 24.591083\n",
      "Epoch 44/100\n",
      "Train Loss: 16.173986\n",
      "Val Loss: 24.632873\n",
      "Epoch 45/100\n",
      "Train Loss: 15.834100\n",
      "Val Loss: 24.305588\n",
      "Epoch 46/100\n",
      "Train Loss: 15.513837\n",
      "Val Loss: 23.829088\n",
      "Epoch 47/100\n",
      "Train Loss: 15.283563\n",
      "Val Loss: 23.688874\n",
      "Epoch 48/100\n",
      "Train Loss: 14.772364\n",
      "Val Loss: 23.173536\n",
      "Epoch 49/100\n",
      "Train Loss: 14.735450\n",
      "Val Loss: 24.174950\n",
      "Epoch 50/100\n",
      "Train Loss: 14.535822\n",
      "Val Loss: 23.622728\n",
      "Epoch 51/100\n",
      "Train Loss: 14.409260\n",
      "Val Loss: 23.236579\n",
      "Epoch 52/100\n",
      "Train Loss: 14.250936\n",
      "Val Loss: 22.975000\n",
      "Epoch 53/100\n",
      "Train Loss: 14.192292\n",
      "Val Loss: 22.905267\n",
      "Epoch 54/100\n",
      "Train Loss: 14.049065\n",
      "Val Loss: 22.839435\n",
      "Epoch 55/100\n",
      "Train Loss: 13.708339\n",
      "Val Loss: 22.789552\n",
      "Epoch 56/100\n",
      "Train Loss: 13.537237\n",
      "Val Loss: 22.878096\n",
      "Epoch 57/100\n",
      "Train Loss: 13.191318\n",
      "Val Loss: 23.220888\n",
      "Epoch 58/100\n",
      "Train Loss: 13.220075\n",
      "Val Loss: 23.760937\n",
      "Epoch 59/100\n",
      "Train Loss: 12.917020\n",
      "Val Loss: 22.757413\n",
      "Epoch 60/100\n",
      "Train Loss: 12.704950\n",
      "Val Loss: 22.439914\n",
      "Epoch 61/100\n",
      "Train Loss: 12.507315\n",
      "Val Loss: 22.277581\n",
      "Epoch 62/100\n",
      "Train Loss: 12.418511\n",
      "Val Loss: 22.346980\n",
      "Epoch 63/100\n",
      "Train Loss: 12.408332\n",
      "Val Loss: 22.248610\n",
      "Epoch 64/100\n",
      "Train Loss: 12.119379\n",
      "Val Loss: 22.262314\n",
      "Epoch 65/100\n",
      "Train Loss: 11.775915\n",
      "Val Loss: 22.180978\n",
      "Epoch 66/100\n",
      "Train Loss: 11.830189\n",
      "Val Loss: 22.203495\n",
      "Epoch 67/100\n",
      "Train Loss: 12.267044\n",
      "Val Loss: 22.458451\n",
      "Epoch 68/100\n",
      "Train Loss: 12.100209\n",
      "Val Loss: 21.921207\n",
      "Epoch 69/100\n",
      "Train Loss: 11.346419\n",
      "Val Loss: 21.678522\n",
      "Epoch 70/100\n",
      "Train Loss: 11.200961\n",
      "Val Loss: 22.431501\n",
      "Epoch 71/100\n",
      "Train Loss: 11.234779\n",
      "Val Loss: 22.081538\n",
      "Epoch 72/100\n",
      "Train Loss: 11.264287\n",
      "Val Loss: 21.868508\n",
      "Epoch 73/100\n",
      "Train Loss: 11.186176\n",
      "Val Loss: 22.631846\n",
      "Epoch 74/100\n",
      "Train Loss: 11.039325\n",
      "Val Loss: 22.119367\n",
      "Epoch 75/100\n",
      "Train Loss: 10.900495\n",
      "Val Loss: 22.775270\n",
      "Epoch 76/100\n",
      "Train Loss: 10.362697\n",
      "Val Loss: 21.535707\n",
      "Epoch 77/100\n",
      "Train Loss: 10.134767\n",
      "Val Loss: 21.695748\n",
      "Epoch 78/100\n",
      "Train Loss: 10.049023\n",
      "Val Loss: 21.880731\n",
      "Epoch 79/100\n",
      "Train Loss: 9.993701\n",
      "Val Loss: 21.758089\n",
      "Epoch 80/100\n",
      "Train Loss: 9.979112\n",
      "Val Loss: 21.870073\n",
      "Epoch 81/100\n",
      "Train Loss: 9.997482\n",
      "Val Loss: 21.959851\n",
      "Epoch 82/100\n",
      "Train Loss: 9.975523\n",
      "Val Loss: 21.986711\n",
      "Epoch 83/100\n",
      "Train Loss: 9.681887\n",
      "Val Loss: 21.808528\n",
      "Epoch 84/100\n",
      "Train Loss: 9.642089\n",
      "Val Loss: 21.820529\n",
      "Epoch 85/100\n",
      "Train Loss: 9.629183\n",
      "Val Loss: 21.914143\n",
      "Epoch 86/100\n",
      "Train Loss: 9.581413\n",
      "Val Loss: 21.867187\n",
      "Epoch 87/100\n",
      "Train Loss: 9.573165\n",
      "Val Loss: 22.023985\n",
      "Epoch 88/100\n",
      "Train Loss: 9.535524\n",
      "Val Loss: 22.124879\n",
      "Epoch 89/100\n",
      "Train Loss: 9.454464\n",
      "Val Loss: 22.002403\n",
      "Epoch 90/100\n",
      "Train Loss: 9.429326\n",
      "Val Loss: 21.942096\n",
      "Epoch 91/100\n",
      "Train Loss: 9.391675\n",
      "Val Loss: 21.974040\n",
      "Epoch 92/100\n",
      "Train Loss: 9.389575\n",
      "Val Loss: 21.970162\n",
      "Epoch 93/100\n",
      "Train Loss: 9.369334\n",
      "Val Loss: 21.992317\n",
      "Epoch 94/100\n",
      "Train Loss: 9.360218\n",
      "Val Loss: 21.987914\n",
      "Epoch 95/100\n",
      "Train Loss: 9.293320\n",
      "Val Loss: 21.984574\n",
      "Epoch 96/100\n",
      "Train Loss: 9.288365\n",
      "Val Loss: 22.023322\n",
      "Epoch 97/100\n",
      "Train Loss: 9.298668\n",
      "Val Loss: 22.048965\n",
      "Epoch 98/100\n",
      "Train Loss: 9.278691\n",
      "Val Loss: 22.054356\n",
      "Epoch 99/100\n",
      "Train Loss: 9.259900\n",
      "Val Loss: 21.997416\n",
      "Epoch 100/100\n",
      "Train Loss: 9.261211\n",
      "Val Loss: 22.049639\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effd144ac5044ae3a0adba09a9b04856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.013 MB of 0.013 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>learning_rate</td><td>█████████████▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train_batch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_epoch_loss</td><td>█▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▄▃▃▃▄▂▂▂▂▂▁▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>17299</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>learning_rate</td><td>3e-05</td></tr><tr><td>train_batch_loss</td><td>12.95627</td></tr><tr><td>train_epoch_loss</td><td>9.26121</td></tr><tr><td>val_loss</td><td>22.04964</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fno2d epochs = 100 batch size = 8 lr = 0.001alpha = 0.9</strong> at: <a href='https://wandb.ai/starslab-iisc/flow-super-resolution-fno/runs/1zcfor49' target=\"_blank\">https://wandb.ai/starslab-iisc/flow-super-resolution-fno/runs/1zcfor49</a><br/> View project at: <a href='https://wandb.ai/starslab-iisc/flow-super-resolution-fno' target=\"_blank\">https://wandb.ai/starslab-iisc/flow-super-resolution-fno</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250122_155108-1zcfor49/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import math\n",
    "from common.config import INPUT_PATH, LR_SHAPE, HR_SHAPE\n",
    "\n",
    "# Constants\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "LR_SHAPE = (16, 16)  # Low resolution shape\n",
    "HR_SHAPE = (128, 128)  # High resolution shape\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "INPUT_PATH = \"/home/diya/Projects/super_resolution/dataset/\"  # Update this path\n",
    "\n",
    "class SpectralConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        \n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights = nn.Parameter(self.scale * torch.randn(in_channels, out_channels, modes1, modes2, 2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        size1, size2 = x.shape[-2], x.shape[-1]\n",
    "        \n",
    "        # Compute Fourier coefficients\n",
    "        x_ft = torch.fft.rfft2(x, norm='ortho')\n",
    "        \n",
    "        # Initialize output array\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, size1, size2//2 + 1, \n",
    "                           device=x.device, dtype=torch.cfloat)\n",
    "        \n",
    "        # Calculate actual modes based on input size\n",
    "        actual_modes1 = min(self.modes1, size1)\n",
    "        actual_modes2 = min(self.modes2, size2//2 + 1)\n",
    "        \n",
    "        # Only multiply the lower Fourier modes\n",
    "        out_ft[:, :, :actual_modes1, :actual_modes2] = (\n",
    "            torch.complex(\n",
    "                torch.einsum(\"bixy,ioxy->boxy\",\n",
    "                           x_ft[:, :, :actual_modes1, :actual_modes2].real,\n",
    "                           self.weights[:, :, :actual_modes1, :actual_modes2, 0]) -\n",
    "                torch.einsum(\"bixy,ioxy->boxy\",\n",
    "                           x_ft[:, :, :actual_modes1, :actual_modes2].imag,\n",
    "                           self.weights[:, :, :actual_modes1, :actual_modes2, 1]),\n",
    "                \n",
    "                torch.einsum(\"bixy,ioxy->boxy\",\n",
    "                           x_ft[:, :, :actual_modes1, :actual_modes2].real,\n",
    "                           self.weights[:, :, :actual_modes1, :actual_modes2, 1]) +\n",
    "                torch.einsum(\"bixy,ioxy->boxy\",\n",
    "                           x_ft[:, :, :actual_modes1, :actual_modes2].imag,\n",
    "                           self.weights[:, :, :actual_modes1, :actual_modes2, 0])\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(size1, size2), norm='ortho')\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.9):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.ssim_window_size = 11\n",
    "        \n",
    "    def ssim(self, img1, img2):\n",
    "        \"\"\"Calculate SSIM between two images\"\"\"\n",
    "        C1 = 0.01 ** 2\n",
    "        C2 = 0.03 ** 2\n",
    "        \n",
    "        # Create a 1D Gaussian kernel\n",
    "        kernel_size = self.ssim_window_size\n",
    "        sigma = 1.5\n",
    "        gauss = torch.Tensor([math.exp(-(x - kernel_size//2)**2/float(2*sigma**2)) \n",
    "                            for x in range(kernel_size)])\n",
    "        gauss = gauss/gauss.sum()\n",
    "        \n",
    "        # Create 2D kernel by outer product\n",
    "        kernel = gauss.unsqueeze(0) * gauss.unsqueeze(1)\n",
    "        kernel = kernel.unsqueeze(0).unsqueeze(0).to(img1.device)\n",
    "        \n",
    "        # Compute means\n",
    "        mu1 = F.conv2d(img1, kernel, padding=kernel_size//2, groups=1)\n",
    "        mu2 = F.conv2d(img2, kernel, padding=kernel_size//2, groups=1)\n",
    "        mu1_sq = mu1 ** 2\n",
    "        mu2_sq = mu2 ** 2\n",
    "        mu1_mu2 = mu1 * mu2\n",
    "        \n",
    "        # Compute variances and covariance\n",
    "        sigma1_sq = F.conv2d(img1 * img1, kernel, padding=kernel_size//2, groups=1) - mu1_sq\n",
    "        sigma2_sq = F.conv2d(img2 * img2, kernel, padding=kernel_size//2, groups=1) - mu2_sq\n",
    "        sigma12 = F.conv2d(img1 * img2, kernel, padding=kernel_size//2, groups=1) - mu1_mu2\n",
    "        \n",
    "        # Compute SSIM\n",
    "        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / \\\n",
    "                   ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "        return ssim_map.mean()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        Combined MSE and SSIM loss\n",
    "        pred, target: (batch_size, channels, height, width)\n",
    "        \"\"\"\n",
    "        # Ensure same shape\n",
    "        assert pred.shape == target.shape, f\"Shape mismatch: {pred.shape} vs {target.shape}\"\n",
    "        \n",
    "        # MSE Loss\n",
    "        mse = F.mse_loss(pred, target)\n",
    "        \n",
    "        # SSIM Loss (1 - SSIM to minimize)\n",
    "        ssim_value = 0\n",
    "        for i in range(pred.shape[1]):  # Compute SSIM for each channel\n",
    "            ssim_value += self.ssim(pred[:,i:i+1], target[:,i:i+1])\n",
    "        ssim_value /= pred.shape[1]\n",
    "        ssim_loss = 1 - ssim_value\n",
    "        \n",
    "        # Combined loss\n",
    "        return self.alpha * mse + (1 - self.alpha) * ssim_loss\n",
    "\n",
    "\n",
    "class FNO2d(nn.Module):\n",
    "    def __init__(self, modes1, modes2, width, in_channels=16, out_channels=128, input_height=16):\n",
    "        super(FNO2d, self).__init__()\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.width = width\n",
    "        \n",
    "        # Input lifting layer\n",
    "        self.fc0 = nn.Linear(in_channels, self.width)\n",
    "        \n",
    "        # Fourier layers\n",
    "        self.conv0 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv1 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv2 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv3 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        \n",
    "        # Spatial convolution layers\n",
    "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
    "        \n",
    "        # Upsampling layers for height only\n",
    "        self.upsample_layers = nn.Sequential(\n",
    "            nn.Upsample(size=(input_height*2, 4), mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(self.width, self.width, 1),\n",
    "            nn.GELU(),\n",
    "            nn.Upsample(size=(input_height*4, 4), mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(self.width, self.width, 1),\n",
    "            nn.GELU(),\n",
    "            nn.Upsample(size=(input_height*8, 4), mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(self.width, self.width, 1),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        \n",
    "        # Output layers\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Conv2d(self.width, 256, 1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(256, out_channels, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, in_channels, height, width]\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Lift to higher dimension\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Fourier layers with residual connections\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "        \n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "        \n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "        \n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "        \n",
    "        # Upsample to target resolution\n",
    "        x = self.upsample_layers(x)\n",
    "        \n",
    "        # Project to output space\n",
    "        x = self.output_layer(x)  # [batch, out_channels, height*8, width]\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    # Initialize wandb\n",
    "    wandb.init(\n",
    "        project=\"flow-super-resolution-fno\",\n",
    "        name='fno2d' + ' epochs = ' + str(NUM_EPOCHS) + \" batch size = \" + str(BATCH_SIZE) + \" lr = \" + str(LEARNING_RATE) + ' alpha = 0.9',\n",
    "        config={\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"epochs\": NUM_EPOCHS,\n",
    "            \"architecture\": \"FNO2D\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Initialize datasets and dataloaders\n",
    "    train_dataset = FlowFieldDataset(mode='train')\n",
    "    val_dataset = FlowFieldDataset(mode='val')\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # Get a sample batch to determine dimensions\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    input_channels = sample_batch[0].shape[1]  # Number of input channels\n",
    "    output_channels = sample_batch[1].shape[1]  # Number of output channels\n",
    "    input_height = sample_batch[0].shape[2]\n",
    "    target_height = sample_batch[1].shape[2]\n",
    "    upscale_factor = target_height // input_height\n",
    "    \n",
    "    print(f\"Input shape: {sample_batch[0].shape}\")\n",
    "    print(f\"Target shape: {sample_batch[1].shape}\")\n",
    "    print(f\"Upscale factor: {upscale_factor}\")\n",
    "    \n",
    "    # Initialize model with correct dimensions\n",
    "    model = FNO2d(\n",
    "        modes1=8, \n",
    "        modes2=8, \n",
    "        width=64,\n",
    "        in_channels=input_channels,\n",
    "        out_channels=output_channels,\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    # Initialize optimizer, scheduler, and loss function\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "    criterion = CombinedLoss(alpha=0.5).to(DEVICE)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        for batch_idx, (X, Y) in enumerate(train_loader):\n",
    "            X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, Y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "            \n",
    "            wandb.log({\n",
    "                \"train_batch_loss\": loss.item(),\n",
    "                \"batch\": batch_idx + epoch * len(train_loader)\n",
    "            })\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X, Y in val_loader:\n",
    "                X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "                pred = model(X)\n",
    "                loss = criterion(pred, Y)\n",
    "                total_val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        \n",
    "        wandb.log({\n",
    "            \"train_epoch_loss\": avg_train_loss,\n",
    "            \"val_loss\": avg_val_loss,\n",
    "            \"epoch\": epoch,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.6f}\")\n",
    "        print(f\"Val Loss: {avg_val_loss:.6f}\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_val_loss,\n",
    "            }, 'best_model.pth')\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    train_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flame",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
